{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AzureComputerVisionAPI.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me06nFaLSEqQ"
      },
      "source": [
        "### What is computer vision?\n",
        "Computer Vision (CV) is a field of artificial intelligence related to the analysis of images and videos. It includes a set of methods that give the computer the ability to\" see \" and extract information from what it sees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7ITemLsSYhW"
      },
      "source": [
        "<img src='https://miro.medium.com/max/875/1*uAeANQIOQPqWZnnuH-VEyw.jpeg' />\n",
        "<img src='https://miro.medium.com/max/625/1*GcI7G-JLAQiEoCON7xFbhg.gif' />\n",
        "<img src=https://miro.medium.com/max/495/1*uoWYsCV5vBU8SHFPAPao-w.gif width=600>\n",
        "<img src='https://miro.medium.com/max/1250/1*_vGloND6yyxFeFH5UyCDVg.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI7F0RMHNwp7"
      },
      "source": [
        "### **Azure Computer Vision is**\n",
        "Text extraction (OCR)\n",
        "Extract printed and handwritten text from images and documents with mixed languages and writing styles.\n",
        "\n",
        "Image understanding\n",
        "Pull from a rich ontology of more than 10,000 concepts and objects to generate value from your visual assets.\n",
        "\n",
        "Spatial analysis\n",
        "Analyze how people move in a space in real time for occupancy count, social distancing and face mask detection.\n",
        "\n",
        "Flexible deployment\n",
        "Run Computer Vision in the cloud or on the edge, in containers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCbzDKNYOBC8"
      },
      "source": [
        "Calling the API using the python SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9qtpNEONqN6"
      },
      "source": [
        "Install SDK and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09KS-uzQt8pe"
      },
      "source": [
        "!pip install --upgrade azure-cognitiveservices-vision-computervision\n",
        "!pip install pillow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy2-iOnYMhQR"
      },
      "source": [
        "# Required variables for operation\n",
        "endpoint = ''\n",
        "subscription_key = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XukVvpSiMhTU"
      },
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Oa81soOVX4"
      },
      "source": [
        "Authorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfA-mZTmMhU_"
      },
      "source": [
        "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7TjBeNCMhXj"
      },
      "source": [
        "# Images for test\n",
        "people_in_helmets = 'https://www.spletnik.ru/img/__post/f5/f53cd4ebe97605812b89db588bbe46b3_963.jpg'\n",
        "couple = 'https://st2.depositphotos.com/1075946/7273/i/600/depositphotos_72738747-stock-photo-couple-relaxing-on-sofa.jpg'\n",
        "street = 'https://media-cdn.tripadvisor.com/media/photo-s/16/1f/60/57/the-street.jpg'\n",
        "remote_image_handw_text_url = \"https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/cognitive-services/Computer-vision/Images/readsample.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWzUJwGvOh4x"
      },
      "source": [
        "#### **Image description**\n",
        "#### The task of identification is to classify the entire image. To do this, the image highlights the key areas and classifies them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80UxBkSLMhbU",
        "outputId": "4c214bb0-d3bd-4b0d-939e-d229482d115f"
      },
      "source": [
        "description_results = computervision_client.describe_image(people_in_helmets)\n",
        "\n",
        "# print(\"Description of remote image: \")\n",
        "if (len(description_results.captions) == 0):\n",
        "    print(\"No description detected.\")\n",
        "else:\n",
        "    for caption in description_results.captions:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'a crowd of people' with confidence 50.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPBsXSfqOob9"
      },
      "source": [
        "#### Categorical analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNnjwqfOO6B7",
        "outputId": "12e6c6ce-30e1-4a81-9900-8d8df16f01d7"
      },
      "source": [
        "remote_image_features = [\"categories\"]\n",
        "# Call API with URL and features\n",
        "categorize_results_remote = computervision_client.analyze_image(people_in_helmets , remote_image_features)\n",
        "\n",
        "# Print results with confidence score\n",
        "print(\"Categories from remote image: \")\n",
        "if (len(categorize_results_remote.categories) == 0):\n",
        "    print(\"No categories detected.\")\n",
        "else:\n",
        "    for category in categorize_results_remote.categories:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categories from remote image: \n",
            "'others_' with confidence 4.69%\n",
            "'outdoor_' with confidence 1.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8hiUmhBOr7W"
      },
      "source": [
        "#### Search for tags by image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuxlsFJsO6FD",
        "outputId": "580872c1-539b-449a-fe96-55d928a41e49"
      },
      "source": [
        "tags_result_remote = computervision_client.tag_image(people_in_helmets)\n",
        "# Print results with confidence score\n",
        "print(\"Tags in the remote image: \")\n",
        "if (len(tags_result_remote.tags) == 0):\n",
        "    print(\"No tags detected.\")\n",
        "else:\n",
        "    for tag in tags_result_remote.tags:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tags in the remote image: \n",
            "'helmet' with confidence 97.58%\n",
            "'person' with confidence 90.37%\n",
            "'personal protective equipment' with confidence 77.68%\n",
            "'goggles' with confidence 69.20%\n",
            "'clothing' with confidence 59.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0g_14MrOwlo"
      },
      "source": [
        "#### **Search for objects in the image**\n",
        "#### The task is to be able to select a certain set of objects from the image. Until the problem is solved in the general case, the algorithm cannot classify random objects in the image. However, it is able to recognize a pre-memorized set of objects with fairly high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkSP9_6YO6JQ",
        "outputId": "a9d3b9f2-68e7-49e7-f12e-f22ddcb10ecd"
      },
      "source": [
        "detect_objects_results_remote = computervision_client.detect_objects(people_in_helmets)\n",
        "\n",
        "# Print detected objects results with bounding boxes\n",
        "print(\"Detecting objects in remote image:\")\n",
        "if len(detect_objects_results_remote.objects) == 0:\n",
        "    print(\"No objects detected.\")\n",
        "else:\n",
        "    for object in detect_objects_results_remote.objects:\n",
        "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
        "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
        "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detecting objects in remote image:\n",
            "object at location 556, 1035, 51, 591\n",
            "object at location 282, 1088, 33, 1080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOywLyx4PO-_"
      },
      "source": [
        "#### Search for faces in an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBPT3udESyuT",
        "outputId": "93b1903c-af0a-4aa4-999a-a830319e64e2"
      },
      "source": [
        "remote_image_features = [\"faces\"]\n",
        "detect_faces_results_remote = computervision_client.analyze_image(couple, remote_image_features)\n",
        "\n",
        "\n",
        "print(\"Faces in the remote image: \")\n",
        "if (len(detect_faces_results_remote.faces) == 0):\n",
        "    print(\"No faces detected.\")\n",
        "else:\n",
        "    for face in detect_faces_results_remote.faces:\n",
        "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
        "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
        "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
        "        face.face_rectangle.top + face.face_rectangle.height))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Faces in the remote image: \n",
            "'Male' of age 50 at location 230, 122, 330, 222\n",
            "'Female' of age 32 at location 352, 166, 442, 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuWDW6YlSyzB",
        "outputId": "974dbc00-891c-45b3-b669-98eae84260a1"
      },
      "source": [
        "remote_image_features = [VisualFeatureTypes.image_type]\n",
        "# Call API with URL and features\n",
        "detect_type_results_remote = computervision_client.analyze_image(street, remote_image_features)\n",
        "\n",
        "# Prints type results with degree of accuracy\n",
        "print(\"Type of remote image:\")\n",
        "if detect_type_results_remote.image_type.clip_art_type == 0:\n",
        "    print(\"Image is not clip art.\")\n",
        "elif detect_type_results_remote.image_type.line_drawing_type == 1:\n",
        "    print(\"Image is ambiguously clip art.\")\n",
        "elif detect_type_results_remote.image_type.line_drawing_type == 2:\n",
        "    print(\"Image is normal clip art.\")\n",
        "else:\n",
        "    print(\"Image is good clip art.\")\n",
        "\n",
        "if detect_type_results_remote.image_type.line_drawing_type == 0:\n",
        "    print(\"Image is not a line drawing.\")\n",
        "else:\n",
        "    print(\"Image is a line drawing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of remote image:\n",
            "Image is not clip art.\n",
            "Image is not a line drawing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUM1H8r0RCNg"
      },
      "source": [
        "#### **Text recognition**\n",
        "#### First, with the help of detection algorithms, the area in which the text is written is highlighted, then text recognition is performed directly, for example, using segmentation algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmovN6h1TvMG"
      },
      "source": [
        "recognize_handw_results = computervision_client.read(remote_image_handw_text_url,  raw=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXOEwOv-VTei",
        "outputId": "8bc7abb8-9d3e-4e6c-c0ab-c4036141dee8"
      },
      "source": [
        "operation_location_remote = recognize_handw_results.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location_remote.split(\"/\")[-1]\n",
        "\n",
        "while True:\n",
        "    get_handw_text_results = computervision_client.get_read_result(operation_id)\n",
        "    if get_handw_text_results.status not in ['notStarted', 'running']:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "if get_handw_text_results.status == OperationStatusCodes.succeeded:\n",
        "    for text_result in get_handw_text_results.analyze_result.read_results:\n",
        "        for line in text_result.lines:\n",
        "            print(line.text)\n",
        "            print(line.bounding_box)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The quick brown fox jumps\n",
            "[38.0, 650.0, 2572.0, 699.0, 2570.0, 854.0, 37.0, 815.0]\n",
            "over\n",
            "[184.0, 1053.0, 508.0, 1044.0, 510.0, 1123.0, 184.0, 1128.0]\n",
            "the lazy dog!\n",
            "[639.0, 1011.0, 1976.0, 1026.0, 1974.0, 1158.0, 637.0, 1141.0]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udv0oVkZP6Is"
      },
      "source": [
        "### **Microsoft Azure** allows you to use computer vision technologies without the need to have highly specialized knowledge in the subject of computer vision, effectively perform tasks in your projects and easily show high results"
      ]
    }
  ]
}